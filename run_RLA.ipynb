{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ab8d26-467d-49f2-9624-9cc05703582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/lguan/miniconda3/envs/rla/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-16 15:21:35.820481: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 15:21:50.960465: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 15:22:31.132618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# for some reason I have to do this manually because the import clip_main\n",
    "# line doesn't work\n",
    "import copy\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "import torch as ch\n",
    "import torch.nn as nn\n",
    "from fastargs import Param, Section\n",
    "from fastargs.validation import And, OneOf\n",
    "import numpy as np\n",
    "import src.config_parse_utils as config_parse_utils\n",
    "from src.eval_utils import evaluate_model\n",
    "from src.trainer import LightWeightTrainer\n",
    "from src.models_and_optimizers import create_clip_model, load_model\n",
    "import src.dist_utils as dist_utils\n",
    "import src.data_utils as data_utils\n",
    "from transformers import EsmTokenizer\n",
    "import src.loader as loaders_utils\n",
    "import sys\n",
    "import webdataset as wds\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "from functools import partial\n",
    "import src.loader as loader_utils\n",
    "import src.zipdataset as zipdataset_utils\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22c7284-add5-4077-95d6-57bc556175d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models_and_optimizers as model_utils\n",
    "from types import SimpleNamespace\n",
    "from clip_main import get_wds_loaders\n",
    "from transformers import EsmTokenizer\n",
    "import src.data_utils as data_utils\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "import esm as esmlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c68069b-1dd5-43cb-badf-537b6df382aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 1, 'batch_size': 1, 'exp_name': '11_13_new_blacklist', 'epochs': 10, 'lr': 0.001, 'weight_decay': 0.001, 'momentum': 0.9, 'lr_peak_epoch': 2, 'label_smoothing': 0.0, 'disable_logging': 0, 'data_root': '/home/gridsan/lguan/keating/pacap/rfdiffusion/20240925/pacap_bind/outputs/wds', 'eval_epochs': 2, 'out_dir': 'runs/', 'only_non_bn_weight_decay': False, 'opt': 'ADAM', 'lr_scheduler': 'cosine', 'mixed_precision': 1, 'max_seq_len': 1024, 'self_supervised': 1, 'burn_in': 0, 'max_coord_len': 2000, 'freeze_llm': 0, 'freeze_text_proj': 0, 'finetune_from': '', 'num_mutations': -1, 'mutation_fwd_method': 'all', 'masked_rate': -1.0, 'masked_mode': 'MASK', 'lm_only_text': 1, 'lm_weight': 1.0, 'resid_weight': 1.0, 'zip_enabled': 0, 'zip_train_format_string': '', 'cath_info_dict': '', 'arch': 'facebook/esm2_t30_150M_UR50D', 'coordinator_hparams': 'terminator_configs/coordinator_broken_merge.json', 'gnn_checkpoint': '', 'gnn_num_pos_embs': 16, 'gnn_zero_out_pos_embs': False, 'language_head': 0, 'language_head_type': 'MLP', 'train_wds_path': 'train/shard-{000000..000019}.tar', 'val_wds_path': 'val/{000000..000004}.tar', 'sharded': 1, 'blacklist_file': '', 'distributed': 0, 'world_size': 1, 'address': 'localhost', 'port': '12355', 'dist_train_len': 170000, 'dist_val_len': 4200}\n"
     ]
    }
   ],
   "source": [
    "## GENERAL SETUP (CHANGE PATHS AS NEEDED)\n",
    "ROOT = \"/home/gridsan/lguan/keating/rla/model_weights\"\n",
    "model_dir = \"version_0/\" \n",
    "dev = 'cuda:0'\n",
    "CLIP_MODE = False\n",
    "root_path = os.path.join(ROOT, model_dir)\n",
    "path = os.path.join(root_path, \"checkpoints/checkpoint_best.pt\")\n",
    "data_root = \"/home/gridsan/lguan/keating/pacap/rfdiffusion/20240925/pacap_bind/outputs/wds\" #\n",
    "args_path = os.path.join(ROOT, model_dir, [u for u in os.listdir(os.path.join(ROOT, model_dir)) if u.endswith('.pt')][0])\n",
    "\n",
    "backwards_compat = {\n",
    "    'masked_rate': -1,\n",
    "    'masked_mode': 'MASK',\n",
    "    'lm_only_text': 1,\n",
    "    'lm_weight': 1,\n",
    "    'resid_weight': 1,\n",
    "    'language_head': False,\n",
    "    'language_head_type': 'MLP',\n",
    "    'zip_enabled': False,\n",
    "    'num_mutations': False,\n",
    "}\n",
    "hparams = torch.load(args_path)\n",
    "args_dict = hparams['args']\n",
    "args_dict['data_root'] = data_root\n",
    "args_dict['batch_size'] = 1\n",
    "args_dict['blacklist_file'] = ''\n",
    "args_dict['num_workers'] = 1\n",
    "for k in backwards_compat.keys():\n",
    "    if k not in args_dict:\n",
    "        args_dict[k] = backwards_compat[k]\n",
    "args = SimpleNamespace(**args_dict)\n",
    "\n",
    "print(vars(args))\n",
    "\n",
    "coordinator_params = data_utils.get_coordinator_params(args.coordinator_hparams)\n",
    "coordinator_params['num_positional_embeddings'] = args.gnn_num_pos_embs\n",
    "coordinator_params['zero_out_pos_embs']= args.gnn_zero_out_pos_embs\n",
    "coordinator_params['clip_mode'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa0497-ab5f-4488-b09a-76129329cdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading state dict from /home/gridsan/lguan/keating/rla/model_weights/version_0/checkpoints/checkpoint_best.pt\n",
      "building model based on path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at /data1/groups/keating_madry/huggingface/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZERO OUT POS EMB False\n",
      "GNN Potts Model Encoder hidden dimensionality is 128\n",
      "freeze_llm False\n",
      "use text proj:  True\n",
      "args: \n",
      "320 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at /data1/groups/keating_madry/huggingface/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## LOAD MODEL (NO CHANGES NEEDED)\n",
    "args_dict['arch'] = '/data1/groups/keating_madry/huggingface/esm2_t30_150M_UR50D'\n",
    "trained_model = model_utils.load_model(path, args_dict['arch'], dev)\n",
    "tokenizer = EsmTokenizer.from_pretrained(args_dict['arch'])\n",
    "\n",
    "esm_arch = args_dict['arch']\n",
    "esm_model = EsmModel.from_pretrained(args_dict['arch']) \n",
    "esm_model = esm_model.to(dev)\n",
    "esm_model.eval()\n",
    "esm, alphabet = esmlib.pretrained.esm2_t30_150M_UR50D()\n",
    "# esm, alphabet = esmlib.pretrained.esm1v_t33_650M_UR90S_1()\n",
    "esm = esm.eval()\n",
    "if dev == 'cuda:0':\n",
    "    esm = esm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e23d79-447d-4a43-931e-6fa028a4306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/lguan/miniconda3/envs/rla/lib/python3.9/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n",
      "/state/partition1/slurm_tmp/27195077.0.0/ipykernel_1533856/2500981057.py:21: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "## LOAD UTIL FUNCTIONS (NO CHANGES NEEDED)\n",
    "%run 2023_12_11_rla_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897b93d-e04a-4bc5-ae88-adb2d4f9fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc166e1c-e7c0-4358-983e-6b54e50a8859",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE RLA SETTING CALCULATIONS (SOME CHANGES POSSIBLE)\n",
    "seq_mask='protein' # 'peptide' to mask peptide sequence, 'protein' to mask protein sequence\n",
    "struct_mask=None # 'peptide' to mask peptide structure, 'protein' to mask protein structure\n",
    "top_k = 30 # Num neighbors, probably want to keep at 30 but can experiment\n",
    "focus = True # RLA calculation setting that limits RLA score to interface, almost certainly want to keep True\n",
    "remove_far = True # Removes residues too far from the interface, likely want to keep True\n",
    "threshold = 1 # Threshold for remove_far calculation, likely want to keep at 1\n",
    "weight_dists = False # Weights RLA score per residue by distance from interface, likely want to keep False\n",
    "pep_weight = 1 # Weight of peptide residues relative to protein residues, likely want to keep at 1\n",
    "force_from_back = False # Define TRUE if masked sequence is always the last chain\n",
    "force_from_front = True # Define TRUE if masked sequence is always the first chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a1277-4b88-4d98-848a-f412f3a9a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATASETS TO EVALUATE (CHANGE AS NEEDED)\n",
    "design_sets = [\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd632200-5960-422e-9b63-d06a8962e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c86a4-b97d-4e2c-9ebf-70c199c1bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: /home/gridsan/lguan/keating/pacap/rfdiffusion/20240925/pacap_bind/outputs/wds/train/shard-{000000..000019}.tar\n",
      "val_path: /home/gridsan/lguan/keating/pacap/rfdiffusion/20240925/pacap_bind/outputs/wds/val/{000000..000004}.tar\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(args.data_root, args.train_wds_path)\n",
    "val_path = os.path.join(args.data_root, args.val_wds_path)\n",
    "print('train_path:', train_path)\n",
    "print('val_path:', val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5757352b-0ef8-45ff-8c71-a30a70d71294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on data.\n",
      "train_path: data.wds\n",
      "val_path: data.wds\n",
      "/home/gridsan/lguan/keating/pacap/rfdiffusion/20240925/pacap_bind/outputs/wds/data.wds False\n",
      "{'max_coords_len': 2000, 'shuffle_coords': False, 'max_seq_len': 1024, 'pos_offset': 128, 'burn_in': 0, 'k_neighbors': 30, 'crop_type': 'absolute', 'shuffle_chains': False, 'num_mutations': 0, 'masked_rate': -1.0, 'masked_mode': 'MASK'}\n",
      "added select filtering... 30\n",
      "0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:09, 308.86it/s]\n",
      "3000it [03:20, 14.93it/s]\n"
     ]
    }
   ],
   "source": [
    "## PERFORMS RLA CALCULATION (NO CHANGES NEEDED)\n",
    "if CLIP_MODE:\n",
    "    feature_getter = get_text_and_image_features_clip\n",
    "else:\n",
    "    feature_getter = get_text_and_image_features\n",
    "    \n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "nclash_dict, Fnat_dict, Fnonnat_dict, LRMS_dict, iRMSDbb_dict, irmsdsc_dict, distance_dict, theta_dict, class_dict = {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "dicts = [nclash_dict, Fnat_dict, Fnonnat_dict, LRMS_dict, iRMSDbb_dict, irmsdsc_dict, distance_dict, theta_dict, class_dict]\n",
    "nclash_data, Fnat_data, Fnonnat_data, LRMS_data, iRMSDbb_data, irmsdsc_data, distance_data, theta_data, class_data = {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "data_dicts = [nclash_data, Fnat_data, Fnonnat_data, LRMS_data, iRMSDbb_data, irmsdsc_data, distance_data, theta_data, class_data]\n",
    "args.batch_size = 1\n",
    "args.zip_enabled = False\n",
    "args.num_mutations = 0\n",
    "args.distributed = 0\n",
    "plot_scores = []\n",
    "plot_weights = []\n",
    "plot_pep_mask = []\n",
    "plot_indices = []\n",
    "plot_X = []\n",
    "plot_seq = []\n",
    "paired_res_scores = {}\n",
    "scores_stats = {'models': [], 'seqs': [], 'rla_scores': []}\n",
    "# result_types = ['nclash', 'fnat', 'fnonnat', 'lrmsd', 'irmsdbb', 'irmsdsc', 'distance', 'theta', 'classification']\n",
    "for design_set in design_sets:\n",
    "    print(f'running on {design_set}.')\n",
    "    args.train_wds_path = f\"{design_set}.wds\"\n",
    "    args.val_wds_path = f\"{design_set}.wds\"\n",
    "    print('train_path:', args.train_wds_path)\n",
    "    print('val_path:', args.val_wds_path)\n",
    "    train_loader, val_loader, train_len, val_len = get_wds_loaders(args, coordinator_params, gpu=None, shuffle_train=False, val_only=True, return_count=False)\n",
    "    lens = {}\n",
    "    for i, b in tqdm(enumerate(val_loader), total=val_len):\n",
    "        lens[b[0]['pdb_id'][0]] = len(b[0]['string_sequence'][0])\n",
    "    MAX_LEN = max(lens.values())\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(val_loader, total=val_len)):\n",
    "        model = batch[0]['pdb_id'][0]\n",
    "        pep_seq = batch[0]['string_sequence'][0][:batch[1]['seq_lens'][0][0]]\n",
    "        chain_lens = torch.zeros(batch[1]['coords'][0].shape[1]).to(device = batch[1]['coords'][0].device)\n",
    "        chain_lens[batch[1]['seq_lens'][0][0]:] = 1\n",
    "        chain_lens_mask = torch.ones(batch[1]['coords'][0].shape[1]).unsqueeze(0).to(dtype=torch.bool, device = batch[1]['coords'][0].device)\n",
    "        batch[1]['chain_lens'] = [chain_lens.unsqueeze(0), chain_lens_mask]\n",
    "        with torch.no_grad():\n",
    "            with autocast(dtype=torch.float16):\n",
    "                output_dict = feature_getter(trained_model, tokenizer, batch, \n",
    "                                             pdb=None, \n",
    "                                             weight_dists=weight_dists, \n",
    "                                             seq_mask=seq_mask, \n",
    "                                             focus=focus, \n",
    "                                             top_k=top_k, \n",
    "                                             struct_mask=struct_mask, \n",
    "                                             remove_far=remove_far, \n",
    "                                             threshold=threshold, \n",
    "                                             dev=dev,\n",
    "                                             force_from_back=force_from_back,\n",
    "                                             force_from_front=force_from_front\n",
    "                                            )\n",
    "                score, scores, plot_scores, plot_weights, plot_pep_mask, plot_indices, plot_X, plot_seq = compute_score(output_dict, weight_dists, MAX_LEN, plot_scores=plot_scores, plot_weights=plot_weights, plot_pep_mask=plot_pep_mask, plot_indices=plot_indices, plot_X=plot_X, plot_seq=plot_seq, is_complex=True)\n",
    "                scores_stats['models'].append(model)\n",
    "                scores_stats['seqs'].append(pep_seq)\n",
    "                paired_res_scores[model] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9eacc10-5ba2-443e-8b2d-86d7db46ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE/LOAD RAW SCORES AND SEQUENCE MAPPINGS (CHANGE JSON WRITING/READING AS NEEDED)\n",
    "import json\n",
    "\n",
    "with open('/home/gridsan/lguan/keating/pacap/rfdiffusion/20240925/pacap_bind/outputs/wds/seq_mapping.json', 'w') as f:\n",
    "    json.dump(scores_stats, f)\n",
    "with open('/home/gridsan/lguan/keating/pacap/rfdiffusion/20240925/pacap_bind/outputs/wds/scores.json', 'w') as f:\n",
    "    json.dump(paired_res_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d14e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
